# Explainable-AI
Explainable AI (XAI) supports transparency by helping users understand and trust machine learning algorithms, answering key questions such as "How?" and "Why?" AI decisions are made. As AI continues to shape workplaces, the level of explanation needed varies based on users’ skills, roles, industries, and specific tasks. This project, Explainable AI: Building Trust by Industry and Occupation, utilizes the Explainable AI Construct (XAIC) framework, developed by Dr. Curt, to address these challenges. The XAIC framework integrates four components: Algorithm Findings (AF), Ability to Abstract (AA), Data Type Understanding (DTU), and Human in the Loop (HIL). 

The research focuses on how human factors—such as education, skill level, job role, industry, and task description—determine the XAI tools and explanations required. Data for this study was sourced from the O*NET database and linked with NAICS and SOC codes to analyze occupational and industry-specific needs. For AF, Natural Language Processing (NLP) was applied to classify detailed work activities into categories representing common machine learning algorithms, using keyword-based methods. AA was predicted using a Random Forest classifier, leveraging inputs such as job zone classifications, STEM knowledge, and the types of data handled (e.g., text, geospatial, image). DTU focused on linking task descriptions to specific data types using keyword extraction with RAKE (Rapid Automatic Keyword Extraction) and vectorization techniques to score understanding levels. HIL was analyzed using sentiment analysis and linear regression to categorize interactions as direct, indirect, opaque, or automated.  

Findings reveal distinct explainability needs across industries and occupations. For example, healthcare roles requiring complex reasoning demand detailed explanations supported by high-level XAI tools, whereas manufacturing roles with practical tasks benefit from simpler, visual explanations. By addressing these needs, the project provides a flexible, human-centered XAI framework that enhances trust, usability, and ethical integration of AI across diverse workplaces. 
